{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeKSlF489t5SxRcvdl12sj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaarangan/text-classification/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2jKBc4HRiuS",
        "outputId": "e9ba8e9c-3f27-42db-c912-4a4e1b92f206"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_tGoy3vQDIj"
      },
      "source": [
        "### -------- Load libraries ------- ###\n",
        "\n",
        "# And pandas for data import\n",
        "import pandas as pd"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGmDyhiFQnmS",
        "outputId": "3a8c275c-02c1-4831-e567-78b7118fb6ca"
      },
      "source": [
        "### --------- Import data --------- ###\n",
        "import os\n",
        "\n",
        "# Import data from csv\n",
        "data = pd.read_csv(\"/tmp/tamil_offensive_full_train.csv\")\n",
        "data_dev = pd.read_csv(\"/tmp/tamil_offensive_full_dev.csv\")\n",
        "\n",
        "# Select required columns\n",
        "data = data[['comment', 'class_type']]\n",
        "data_dev = data_dev[['comment', 'class_type']]\n",
        "\n",
        "# Remove a row if any of the three remaining columns are missing\n",
        "data = data.dropna();\n",
        "data_dev = data_dev.dropna()\n",
        "\n",
        "print(data)\n",
        "print(data_dev)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 comment                           class_type\n",
            "0                      movie vara level la Erika poguthu                        Not_offensive\n",
            "1      I love Ajith Kumar Vivegam movie inki mjy bht ...                            not-Tamil\n",
            "2              Padam nalla comedy padama irukum polaye..                        Not_offensive\n",
            "3      karthick subburaj anne .... intha padam vetri ...                        Not_offensive\n",
            "4      ‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å                        Not_offensive\n",
            "...                                                  ...                                  ...\n",
            "35134  Trending number #2 idhukku nammalam karanamnu ...                        Not_offensive\n",
            "35135                                 Movie script super   athuvum HIP HOP Tamizha music vera\n",
            "35136                       Just 3k likes for 300k likes                        Not_offensive\n",
            "35137                          Aaloo le lo. Kanda le lo.                            not-Tamil\n",
            "35138  ‡Æ®‡Ææ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≤‡Øç ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç  ‡Æµ‡Æ©‡Øç‡Æ©‡Æø‡ÆØ‡Æ∞‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æ§‡Æø‡Æ∞‡Øå‡Æ™‡Æ§‡Æø ‡Æ™‡Æü...                        Not_offensive\n",
            "\n",
            "[34863 rows x 2 columns]\n",
            "                                                comment                       class_type\n",
            "0                     Handsome hunk  keri vaa thalaivaa                    Not_offensive\n",
            "1     ‡Æ§‡ØÜ‡Æ©‡Øç‡Æï‡Ææ‡Æö‡Æø ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æ®‡Ææ‡Æü‡Ææ‡Æ∞‡Øç ‡Æö‡ÆÆ‡ØÅ‡Æ§‡Ææ‡ÆØ‡ÆÆ‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡Ææ‡Æ¥‡Øç...                    Not_offensive\n",
            "2     je vous aime bravo pour clip de merde que j √©c...                        not-Tamil\n",
            "3     ‡Æö‡Æø‡Æ±‡Æ™‡Øç‡Æ™‡ØÅ..... ‡ÆÆ‡Øá‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ©‡Øç‡Æ± ‡Æ™‡Æü‡Øà‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æø‡Æï ‡ÆÖ...                    Not_offensive\n",
            "4                   Vera level BGM .. semma  trailer. ü§û                    Not_offensive\n",
            "...                                                 ...                              ...\n",
            "4383  ‡ÆÆ‡Æø‡Æ∑‡Øç‡Æï‡Æø‡Æ©‡Øç  - ‡Æö‡Æø‡Æ©‡Æø‡ÆÆ‡Ææ‡Æµ‡Æø‡Æ©‡Øç ‡Æö‡Æ≤‡Æø‡Æ§‡Øç‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ© ‡Æµ‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï...                    Not_offensive\n",
            "4384  Sivaji - Bhajii Sapdu Petta - Sweet Sapdu  Ser...                  Same Modulation\n",
            "4385                     8k dislike sure all vijay fans  Offensive_Targeted_Insult_Other\n",
            "4386        Lady super star Manju warrier Fans Hit like                    Not_offensive\n",
            "4387  Very nice .......kandippa theater la paakanum paa                    Not_offensive\n",
            "\n",
            "[4354 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (13,14,16,17,18,20,21,22,23,24,25,26,27,28,29,32,35,37,39,45,57,58) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jCgHcJSmILF"
      },
      "source": [
        "### -------- Load libraries ------- ###\n",
        "\n",
        "# copy + klearn because you allways need sklearn\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcjLMKKbT3En",
        "outputId": "3a039984-5a81-4594-a278-a0a135e8acf3"
      },
      "source": [
        "# Remove rows, where the label is present only ones (can't be split)\n",
        "data = data.groupby('class_type').filter(lambda x : len(x) > 1)\n",
        "data_dev = data_dev.groupby('class_type').filter(lambda x : len(x) > 1)\n",
        "\n",
        "# Remove rows, where the label is present only in the array\n",
        "data = data[data.class_type.isin(['Not_offensive', 'Offensive_Targeted_Insult_Other', 'Offensive_Targeted_Insult_Individual', 'Offensive_Targeted_Insult_Group', 'not_Tamil', 'Offensive_Untargetede'])]\n",
        "data_dev = data_dev[data_dev.class_type.isin(['Not_offensive', 'Offensive_Targeted_Insult_Other', 'Offensive_Targeted_Insult_Individual', 'Offensive_Targeted_Insult_Group', 'not_Tamil', 'Offensive_Untargetede'])]\n",
        "\n",
        "# Set your model output as categorical and save in new label col\n",
        "data['class_type_label'] = pd.Categorical(data['class_type'])\n",
        "data_dev['class_type_label'] = pd.Categorical(data_dev['class_type'])\n",
        "\n",
        "# Transform your output to numeric\n",
        "data['class_type'] = data['class_type_label'].cat.codes\n",
        "data_dev['class_type'] = data_dev['class_type_label'].cat.codes\n",
        "\n",
        "# # Split into train and test - stratify over Issue\n",
        "# data, data_test = train_test_split(data, test_size = 0.2, stratify = data[['class_type']])\n",
        "\n",
        "\n",
        "print(data)\n",
        "print(data_dev)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                 comment  ...                      class_type_label\n",
            "0                      movie vara level la Erika poguthu  ...                         Not_offensive\n",
            "2              Padam nalla comedy padama irukum polaye..  ...                         Not_offensive\n",
            "3      karthick subburaj anne .... intha padam vetri ...  ...                         Not_offensive\n",
            "4      ‡Æï‡Æµ‡ØÅ‡Æ£‡Øç‡Æü‡Æ∞‡Øç ‡Æ§‡Øá‡Æµ‡Æ∞‡Øç.‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡ØÜ‡Æ±‡Øç‡Æ±‡Æø ‡Æ™‡ØÜ‡Æ± ‡Æµ‡Ææ‡Æ¥‡Øç‡Æ§‡Øç‡Æ§‡ØÅ‡Æï‡Øç‡Æï‡Æ≥‡Øç ü¶Å  ...                         Not_offensive\n",
            "5      ippo intha trailer ah parkuravana oru like pod...  ...                         Not_offensive\n",
            "...                                                  ...  ...                                   ...\n",
            "35132   Thala ulllaipa uyirvu ku rolemodelll nenka thala  ...                         Not_offensive\n",
            "35133  inda pathi like thala fans um thandrukanga da ...  ...  Offensive_Targeted_Insult_Individual\n",
            "35134  Trending number #2 idhukku nammalam karanamnu ...  ...                         Not_offensive\n",
            "35136                       Just 3k likes for 300k likes  ...                         Not_offensive\n",
            "35138  ‡Æ®‡Ææ‡ÆÆ‡Æï‡Øç‡Æï‡Æ≤‡Øç ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç  ‡Æµ‡Æ©‡Øç‡Æ©‡Æø‡ÆØ‡Æ∞‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æ§‡Æø‡Æ∞‡Øå‡Æ™‡Æ§‡Æø ‡Æ™‡Æü...  ...                         Not_offensive\n",
            "\n",
            "[30933 rows x 3 columns]\n",
            "                                                comment  ...                 class_type_label\n",
            "0                     Handsome hunk  keri vaa thalaivaa  ...                    Not_offensive\n",
            "1     ‡Æ§‡ØÜ‡Æ©‡Øç‡Æï‡Ææ‡Æö‡Æø ‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç ‡Æ®‡Ææ‡Æü‡Ææ‡Æ∞‡Øç ‡Æö‡ÆÆ‡ØÅ‡Æ§‡Ææ‡ÆØ‡ÆÆ‡Øç ‡Æö‡Ææ‡Æ∞‡Øç‡Æ™‡Ææ‡Æï ‡Æµ‡Ææ‡Æ¥‡Øç...  ...                    Not_offensive\n",
            "3     ‡Æö‡Æø‡Æ±‡Æ™‡Øç‡Æ™‡ØÅ..... ‡ÆÆ‡Øá‡Æ≤‡ØÅ‡ÆÆ‡Øç ‡Æá‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ©‡Øç‡Æ± ‡Æ™‡Æü‡Øà‡Æ™‡Øç‡Æ™‡ØÅ‡Æï‡Æ≥‡Øç ‡ÆÆ‡Æø‡Æï ‡ÆÖ...  ...                    Not_offensive\n",
            "4                   Vera level BGM .. semma  trailer. ü§û  ...                    Not_offensive\n",
            "5     ‡Æé‡Æ©‡Øç‡Æ©‡Æü‡Ææ ‡Æ™‡Æ£‡Øç‡Æ£‡Æø ‡Æµ‡Æö‡Øç‡Æö‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡ØÄ‡Æô‡Øç‡Æï ?!!!! ‡ÆÖ‡Æ®‡Øç‡Æ§ ‡ÆÖ‡ÆÆ‡Øç‡ÆÆ‡Ææ‡Æµ ...  ...  Offensive_Targeted_Insult_Group\n",
            "...                                                 ...  ...                              ...\n",
            "4382  3 Times kku mela pathavanga yarellam like pann...  ...                    Not_offensive\n",
            "4383  ‡ÆÆ‡Æø‡Æ∑‡Øç‡Æï‡Æø‡Æ©‡Øç  - ‡Æö‡Æø‡Æ©‡Æø‡ÆÆ‡Ææ‡Æµ‡Æø‡Æ©‡Øç ‡Æö‡Æ≤‡Æø‡Æ§‡Øç‡Æ§‡ØÅ ‡Æ™‡Øã‡Æ© ‡Æµ‡Æü‡Øç‡Æü‡Æ§‡Øç‡Æ§‡Æø‡Æ±‡Øç‡Æï...  ...                    Not_offensive\n",
            "4385                     8k dislike sure all vijay fans  ...  Offensive_Targeted_Insult_Other\n",
            "4386        Lady super star Manju warrier Fans Hit like  ...                    Not_offensive\n",
            "4387  Very nice .......kandippa theater la paakanum paa  ...                    Not_offensive\n",
            "\n",
            "[3868 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjNECnjyfhN5"
      },
      "source": [
        "### -------- Load libraries ------- ###\n",
        "# Load Huggingface transformers\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkvZJs5QQ-KG",
        "outputId": "dc6886f0-d926-47ce-df84-426fd313861a"
      },
      "source": [
        "### --------- Setup BERT ---------- ###\n",
        "\n",
        "# Name of the BERT model to use\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# Load transformers config and set output_hidden_states to False\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "\n",
        "# Load the Transformers BERT model\n",
        "transformer_model = TFBertModel.from_pretrained(model_name, config = config)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOh-kukFhNfh"
      },
      "source": [
        "# Then what you need from tensorflow.keras\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.initializers import TruncatedNormal"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JklUuiM5Q_9D",
        "outputId": "5bf0e1f0-c135-443c-b70f-60ce63627652"
      },
      "source": [
        "### ------- Build the model ------- ###\n",
        "\n",
        "# Load the MainLayer\n",
        "bert = transformer_model.layers[0]\n",
        "\n",
        "# Max length of tokens\n",
        "max_length = 100\n",
        "\n",
        "# Build your model input\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "attention_mask = Input(shape=(max_length,), name='attention_mask', dtype='int32')\n",
        "inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
        "\n",
        "# Load the Transformers BERT model as a layer in a Keras model\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "# Then build your model output\n",
        "class_type = Dense(units=len(data.class_type_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='class_type')(pooled_output)\n",
        "outputs = {'class_type': class_type}\n",
        "\n",
        "# And combine it all in a model object\n",
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "\n",
        "# Take a look at the model\n",
        "model.summary()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "attention_mask (InputLayer)     [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_ids (InputLayer)          [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   attention_mask[0][0]             \n",
            "                                                                 input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pooled_output (Dropout)         (None, 768)          0           bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "class_type (Dense)              (None, 5)            3845        pooled_output[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,486,085\n",
            "Trainable params: 109,486,085\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POHXwS79foUE"
      },
      "source": [
        "### -------- Load libraries ------- ###\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNfuPB_DRCWq",
        "outputId": "5b29c9d3-e02e-4426-bcfe-6cc448c8f509"
      },
      "source": [
        "### ------- Train the model ------- ###\n",
        "\n",
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-05,\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'class_type': CategoricalCrossentropy(from_logits = True)}\n",
        "metric = {'class_type': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_class_type = to_categorical(data['class_type'])\n",
        "\n",
        "# Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=data['comment'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids'], 'attention_mask': x['attention_mask']},\n",
        "    y={'class_type': y_class_type},\n",
        "    validation_split=0.2,\n",
        "    batch_size=64,\n",
        "    epochs=1)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "387/387 [==============================] - 546s 1s/step - loss: 0.7908 - accuracy: 0.7605 - val_loss: 0.6398 - val_accuracy: 0.7818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz4e439BRC5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fbd9f0-771f-4c87-abe0-72c05a405b74"
      },
      "source": [
        "### ----- Evaluate the model ------ ###\n",
        "\n",
        "# Ready test data\n",
        "test_y_class_type = to_categorical(data_dev['class_type'])\n",
        "test_x = tokenizer(\n",
        "    text=data_dev['comment'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "\n",
        "# Run evaluation\n",
        "model_eval = model.evaluate(\n",
        "    x={'input_ids': test_x['input_ids'], 'attention_mask': test_x['attention_mask']},\n",
        "    y={'class_type': test_y_class_type}\n",
        ")"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121/121 [==============================] - 29s 237ms/step - loss: 0.6557 - accuracy: 0.7702\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}